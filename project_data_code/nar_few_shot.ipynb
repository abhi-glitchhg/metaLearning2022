{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmshroff/metaLearning2022/blob/main/project_data_code/nar_few_shot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade --force-reinstall --no-deps kaggle"
      ],
      "metadata": {
        "id": "iivL_SSLohA9"
      },
      "id": "iivL_SSLohA9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "W1gmpI21om-f"
      },
      "id": "W1gmpI21om-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.kaggle\n",
        "!mv ./kaggle.json /root/.kaggle/.\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "NadxX1y5onmE"
      },
      "id": "NadxX1y5onmE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list --user gmshroff"
      ],
      "metadata": {
        "id": "ygUiLREisevj"
      },
      "id": "ygUiLREisevj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d gmshroff/few-shot-nar"
      ],
      "metadata": {
        "id": "P5LrfKo3ovEf"
      },
      "id": "P5LrfKo3ovEf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q few-shot-nar.zip"
      ],
      "metadata": {
        "id": "lNpnhgMroyRV"
      },
      "id": "lNpnhgMroyRV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "e_zb2LfoyBB8"
      },
      "id": "e_zb2LfoyBB8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b7c5f5-6919-4b63-bbc3-971eaccee0c0",
      "metadata": {
        "id": "73b7c5f5-6919-4b63-bbc3-971eaccee0c0"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf7eaa57-1ab3-4a6c-aab2-4f1efa3a3387",
      "metadata": {
        "id": "bf7eaa57-1ab3-4a6c-aab2-4f1efa3a3387"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pathlib\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch\n",
        "from torchvision.io import read_image as tv_read_image\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# def read_image(path):\n",
        "#     return tv_read_image(str(path))\n",
        "def read_image(path):\n",
        "    return transforms.ToTensor()(Image.open(str(path)))\n",
        "\n",
        "Example = namedtuple('Example', ['input', 'options', 'solution'])\n",
        "Problem = namedtuple('Problem', ['examples', 'query', 'query_options', 'solution', 'program'])\n",
        "\n",
        "class AnalogicalReasoningDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Analogical Reasoning Classification Dataset\n",
        "\n",
        "    This dataset consists of analogical reasoning [1] classification problems.\n",
        "    Each problem is made up of 5 parts\n",
        "        1. Examples: a list of examples of a program where each example \n",
        "        is a tuple made of -\n",
        "            i. Input image\n",
        "            ii. Options for the output image among which one is the correct answer\n",
        "            iii. The index of the correct option \n",
        "        2. Query: the query image for which to predict the correct option\n",
        "        when the program (which should be inferred from the examples) is applied\n",
        "        3. Query Options: the options for the output when the program inferred\n",
        "        from the the examples is applied to the query\n",
        "        4. Solution: the index of the correct option \n",
        "        5. Program: the ground truth program that generated the query image\n",
        "    \n",
        "    Calling `__getitem__` on this dataset returns a tuple containing \n",
        "        1. The problem with symbolic descriptions of the images\n",
        "        2. The problem with images themselves\n",
        "    Each of the above is a namedtuple with the following fields:\n",
        "        1. `examples`: a list of examples of a program where each example\n",
        "        is a tuple made of `input`, `options`, and `solution`.\n",
        "        2. `query`\n",
        "        3. `query_options`\n",
        "        4. `solution`\n",
        "        5. `program`\n",
        "    Since this is a named tuple you can access these fields using their names.\n",
        "    For example `problem.examples[0].input`\n",
        "\n",
        "    This can be considered as a meta learning [2] task where each task consits \n",
        "    of training data (examples) and test data (query). You can split this dataset\n",
        "    into meta-training and meta-test subsets. The meta-training subset can be\n",
        "    used to train your model to be able to solve the query task given the examples.\n",
        "    The meta-test subset can be used to test your model's performance.\n",
        "\n",
        "    Args:\n",
        "        problems_file: path to a json file containing the problems\n",
        "        image_dir: path to the directory containing the images\n",
        "        size (int): size of the dataset (should be given in the name of image_dir)\n",
        "\n",
        "    References:\n",
        "        [1] https://arxiv.org/abs/2111.10361\n",
        "        [2] https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html#define-the-meta-learning-problem\n",
        "    \"\"\"\n",
        "    def __init__(self, problems_file, image_dir, size):\n",
        "        self.problems_file = problems_file\n",
        "        self.image_dir = pathlib.Path(image_dir)\n",
        "        self.size = size\n",
        "\n",
        "        with open(self.problems_file, \"r\") as f:\n",
        "            self.problems = json.load(f)[:size]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.problems)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        problem = self.problems[idx]\n",
        "\n",
        "        return Problem._make((\n",
        "            [Example._make(e) for e in problem[0]],\n",
        "            problem[1],\n",
        "            problem[2],\n",
        "            problem[3],\n",
        "            problem[4],\n",
        "        )), Problem._make((\n",
        "            [\n",
        "                Example._make((\n",
        "                    read_image(self.image_dir/f\"{idx}_{eidx}_input.png\"),\n",
        "                    [\n",
        "                        read_image(self.image_dir/f\"{idx}_{eidx}_{oidx}_option.png\")\n",
        "                        for oidx in range(len(problem[0][eidx][1]))\n",
        "                    ],\n",
        "                    problem[0][eidx][2]\n",
        "                ))\n",
        "                for eidx in range(len(problem[0]))\n",
        "            ],\n",
        "            read_image(self.image_dir/f\"{idx}_query.png\"),\n",
        "            [\n",
        "                read_image(self.image_dir/f\"{idx}_{oidx}_query_option.png\")\n",
        "                for oidx in range(len(problem[2]))\n",
        "            ],\n",
        "            problem[3],\n",
        "            problem[4]\n",
        "        ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01588fea-2f8f-4cc7-8af0-740c54fcbc2a",
      "metadata": {
        "id": "01588fea-2f8f-4cc7-8af0-740c54fcbc2a"
      },
      "outputs": [],
      "source": [
        "narDS=AnalogicalReasoningDataset(\"./problems_10k.json\",\"./nar_classification_dataset_images_10k/images_large\",100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00fa15a0-96bc-4ff1-9eb8-1b5c9c167066",
      "metadata": {
        "id": "00fa15a0-96bc-4ff1-9eb8-1b5c9c167066"
      },
      "outputs": [],
      "source": [
        "ex=narDS.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d64c95-fc47-4cbc-be03-5cb93fd7d57f",
      "metadata": {
        "id": "50d64c95-fc47-4cbc-be03-5cb93fd7d57f"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.array(ex[1].examples[2].input[0,:,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d98d74-97f2-459c-b427-7fd26517710b",
      "metadata": {
        "id": "45d98d74-97f2-459c-b427-7fd26517710b"
      },
      "outputs": [],
      "source": [
        "transforms.ToPILImage()(ex[1].examples[2].options[ex[1].examples[2].solution])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b5fb303-2516-4316-b5d7-c4f87a494f97",
      "metadata": {
        "id": "0b5fb303-2516-4316-b5d7-c4f87a494f97"
      },
      "outputs": [],
      "source": [
        "transforms.ToPILImage()(ex[1].examples[2].input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ce0615-4e3d-46e2-8d53-6bcb85783a1a",
      "metadata": {
        "id": "38ce0615-4e3d-46e2-8d53-6bcb85783a1a"
      },
      "outputs": [],
      "source": [
        "transforms.ToPILImage()(ex[1].examples[2].options[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ddabff-1f63-4f32-ae9f-29c238a6ce0d",
      "metadata": {
        "id": "64ddabff-1f63-4f32-ae9f-29c238a6ce0d"
      },
      "outputs": [],
      "source": [
        "ex[1].examples[2].input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d3284b1-c8cb-41da-bdc5-c6159ab294cc",
      "metadata": {
        "id": "5d3284b1-c8cb-41da-bdc5-c6159ab294cc"
      },
      "outputs": [],
      "source": [
        "narDS.problems[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "304c5b70-9d03-44e7-8fb6-0e4d618cecef",
      "metadata": {
        "id": "304c5b70-9d03-44e7-8fb6-0e4d618cecef"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "nar_few_shot.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}